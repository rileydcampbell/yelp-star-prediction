{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SQLContext\n",
    "conf = pyspark.SparkConf()\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "# from pyspark import SparkContext as sc, SparkConf, SQLContext as sqlContext\n",
    "import sys\n",
    "sys.path.insert(1, 'Classifier')\n",
    "import Classifier\n",
    "from Classifier import YelpClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_line_to_review(input_line):\n",
    "    # some reviews may be malformed/not contain all of the fields\n",
    "    tokens = input_line\n",
    "    review_id, num_stars, review_text = tokens[0], tokens[1], tokens[2]\n",
    "    return [(review_id, num_stars, review_text)]\n",
    "\n",
    "def input_line_to_review_no_label(input_line):\n",
    "    # some reviews may be malformed/not contain all of the fields\n",
    "    tokens = input_line\n",
    "    review_id, review_text = tokens[0], tokens[2]\n",
    "    return [(review_id, review_text)]\n",
    "\n",
    "def get_review_stars(actual_rdd):\n",
    "    # Transformations:\n",
    "    # 1. [(review_id, num_stars, review_text_as_string)] --> [(review_id, true_num_stars)]\n",
    "\n",
    "    reviews_and_stars = actual_rdd \\\n",
    "                        .flatMap(filter_only_review_id_and_stars) \\\n",
    "                        .sortByKey()\n",
    "\n",
    "    return reviews_and_stars\n",
    "\n",
    "# Converts a review to a key-value pair of only review ID and its number of stars\n",
    "def filter_only_review_id_and_stars(review):\n",
    "    review_id, num_stars, review_text = review\n",
    "    return [(review_id, num_stars)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initRDDs(training_data_file, test_data_file):\n",
    "\n",
    "    # takes text file of reviews --> RDD\n",
    "    try:\n",
    "        train_rdd = training_data_file.flatMap(input_line_to_review)\n",
    "        test_rdd = test_data_file.flatMap(input_line_to_review_no_label)\n",
    "        actual_rdd = test_data_file.flatMap(input_line_to_review)\n",
    "        return train_rdd, test_rdd, actual_rdd\n",
    "    except:\n",
    "        print >> sys.stderr, \"Unable to load train and test data files\"\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = sqlContext.read.json(\"/Users/rileycampbell/Desktop/GitHub/yelp-star-prediction/yelp_dataset/review.json\")\n",
    "review_rows = reviews.select(\"review_id\", \"stars\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66835, 6670)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split = review_rows.randomSplit([0.01, 0.001, 0.989])\n",
    "split[2] = 0\n",
    "\n",
    "train_split, test_split = split[0], split[1]\n",
    "# print(train_split.count())\n",
    "length1 = train_split.count()\n",
    "length2 = test_split.count()\n",
    "print(length1, length2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst = []\n",
    "for row in train_split.collect():\n",
    "    new_text = str(row[2].encode(\"utf-8\"))\n",
    "    train_lst.append((row[0], row[1], new_text))\n",
    "\n",
    "test_lst = []\n",
    "for row in test_split.head(1000):\n",
    "    new_text = str(row[2].encode(\"utf-8\"))\n",
    "    test_lst.append((row[0], row[1], new_text))\n",
    "\n",
    "training_file = sc.parallelize(train_lst)\n",
    "test_file = sc.parallelize(test_lst)\n",
    "\n",
    "\n",
    "train_rdd, test_rdd, actual_rdd = initRDDs(training_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "\n",
    "# Star bins used for classifying Yelp reviews\n",
    "STARS = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "\n",
    "class YelpClassifier(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.NUM_REVIEWS = {} # num_stars -> # of reviews with num_stars\n",
    "        self.NUM_WORDS = {} # num_stars -> # of words total across all reviews with num_stars\n",
    "        self.LIKELIHOODS = {} # word -> P(word | num_stars)\n",
    "        self.PRIORS = {} # num_stars -> P(num_stars)\n",
    "\n",
    "    ######################################################\n",
    "    ################# DRIVER FUNCTIONS ##################\n",
    "    ######################################################\n",
    "\n",
    "    def train(self, train_rdd):\n",
    "        self.NUM_REVIEWS, self.NUM_WORDS = self.calculate_num_reviews_and_words_per_num_stars(train_rdd)\n",
    "        self.PRIORS = self.calculate_priors()\n",
    "        self.LIKELIHOODS = self.calculate_likelihoods(train_rdd)\n",
    "\n",
    "    def classify(self, test_rdd):\n",
    "        predictions = self.classify_reviews(test_rdd)\n",
    "        predictedReviews = predictions.collect()\n",
    "        return predictedReviews\n",
    "\n",
    "    ######################################################\n",
    "    ################# PYSPARK FUNCTIONS ##################\n",
    "    ######################################################\n",
    "\n",
    "    # Given the reviews in train_rdd, calculates P(word | num_stars) for every word found in a review,\n",
    "    # i.e. the likelihood of a word in a review given the number of stars that review received.\n",
    "    # The likelihood is calculated as, across all of the reviews given NUM_STARS:\n",
    "    # P(WORD | NUM_STARS) = # of occurences of WORD / # of total words in all reviews with NUM_STARS\n",
    "    def calculate_likelihoods(self, train_rdd):\n",
    "        # Transformations:\n",
    "        # 1. (review_id, num_stars, review_text_as_string) --> [((num_stars, word_in_review), 1)]\n",
    "        # 2. [((num_stars, word_in_review), 1)] --> [((num_stars, word_in_review), num_reviews_of_num_stars_with_word)]\n",
    "        # 3. [((num_stars, word_in_review), num_reviews_with_word_and_stars)] --> [(num_stars, {word : probability_in_review_of_num_stars})]\n",
    "        # 4. [(num_stars, {word1 : prob1, word2 : prob2, word3 : prob3...})]\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "        class_likelihoods = train_rdd \\\n",
    "                            .flatMap(self.review_to_word_counts) \\\n",
    "                            .reduceByKey(self.add_review_counts) \\\n",
    "                            .map(self.counts_to_probabilities) \\\n",
    "                            .aggregateByKey({}, self.combine_probability_tables, self.combine_probability_tables)\n",
    "\n",
    "        LIKELIHOODS = {}\n",
    "        for num_stars, likelihood in class_likelihoods.collect():\n",
    "            LIKELIHOODS[int(num_stars)] = likelihood\n",
    "\n",
    "        return LIKELIHOODS\n",
    "\n",
    "\n",
    "    # Calculate number of reviews per number of stars\n",
    "    def calculate_num_reviews_and_words_per_num_stars(self, train_rdd):\n",
    "        # Transformations:\n",
    "        # 1. (review_id, num_stars, review_text_as_string) --> [(num_stars, (1, num_words))]\n",
    "        # 2. [(num_stars, (1, num_words))] --> [(num_stars, (num_reviews_of_num_stars, num_words_total_of_num_stars))]\n",
    "\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "        num_reviews_words_per_num_stars = train_rdd \\\n",
    "                        .map(self.review_to_num_stars_num_words)\\\n",
    "                        .reduceByKey(self.add_review_and_word_counts)\n",
    "\n",
    "\n",
    "        NUM_REVIEWS = {}\n",
    "        NUM_WORDS = {}\n",
    "        for num_stars, counts in num_reviews_words_per_num_stars.collect():\n",
    "            num_reviews, num_words = counts\n",
    "            NUM_REVIEWS[int(num_stars)] = int(num_reviews)\n",
    "            NUM_WORDS[int(num_stars)] = int(num_words)\n",
    "\n",
    "        return NUM_REVIEWS, NUM_WORDS\n",
    "\n",
    "    # Calculates priors for each class as: P(num_stars) = # of reviews with num_stars / # of total reviews\n",
    "    def calculate_priors(self):\n",
    "        total_num_reviews = 0\n",
    "        for num_stars, num_reviews in self.NUM_REVIEWS.items():\n",
    "            total_num_reviews += num_reviews\n",
    "\n",
    "        PRIORS = self.NUM_REVIEWS.copy()\n",
    "        for num_stars, num_reviews in PRIORS.items():\n",
    "            prior = float(num_reviews) / float(total_num_reviews)\n",
    "            PRIORS[num_stars] = prior\n",
    "\n",
    "        return PRIORS\n",
    "\n",
    "    def classify_reviews(self, test_rdd):\n",
    "        # Transformations:\n",
    "        # 1. (review_id, num_stars, review_text_as_string) --> [((num_stars1, review_id) word1), ((num_stars1, review_id), word2), ((num_stars2, review_id), word1)...]\n",
    "        # 2. [((num_stars1, review_id) word1), ((num_stars1, review_id), word2), ((num_stars2, review_id), word1)...] ->\n",
    "        #    [((num_stars1, review_id) log_p_word1), ((num_stars1, review_id), log_p_word2), ((num_stars2, review_id), log_p_word1)...]\n",
    "        # 3. [((num_stars1, review_id) p_word1), ((num_stars1, review_id), p_word2)] --> [((num_stars1, review_id), p_word2_sum)]\n",
    "        # 4. [((num_stars1, review_id), log_likelihood)] --> [((num_stars1, review_id), log_posterior)]\n",
    "        # 5. [((num_stars1, review_id), log_posterior)] --> [(review_id, (num_stars1, log_posterior1)]\n",
    "        # 6. [(review_id, (num_stars1, log_posterior1)] --> [(review_id, (num_stars, max_posterior)]\n",
    "        # 7. [(review_id, (num_stars, max_posterior)] --> [(review_id, most_likely_num_stars)]\n",
    "        predictions = test_rdd \\\n",
    "                            .flatMap(self.review_to_num_stars_and_word_pairs) \\\n",
    "                            .map(self.words_to_log_likelihoods) \\\n",
    "                            .reduceByKey(self.add_log_likelihoods) \\\n",
    "                            .map(self.likelihood_to_posterior) \\\n",
    "                            .map(self.review_id_only_as_key) \\\n",
    "                            .reduceByKey(self.find_max_posterior) \\\n",
    "                            .sortByKey()\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    # ___________________________________________________ #\n",
    "    # ____________TRAINING HELPERS_______________________ #\n",
    "    # ___________________________________________________ #\n",
    "\n",
    "    # ____________calculate_likelihoods() helpers________ #\n",
    "\n",
    "\n",
    "    # Maps the words in a review to pairs of that word, the number of stars\n",
    "    # of the review that the word was in, and the count of that word.\n",
    "    # Review is of the format (review_id, num_stars, review_text_as_string)\n",
    "    # Converts to [(key, 1)] where key = (num_stars, word_in_review)\n",
    "    @staticmethod\n",
    "    def review_to_word_counts(review):\n",
    "        lst = []\n",
    "        for elem in review[2].split(\" \"):\n",
    "            lst.append(((review[1], elem), 1.0))\n",
    "        return lst\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "\n",
    "    # Adds two review counts together\n",
    "    @staticmethod\n",
    "    def add_review_counts(count1, count2):\n",
    "        return count1 + count2\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    # Helper function to compute the likelihood of a word with Laplace smoothing\n",
    "    def compute_likelihood(self, count_of_word, num_stars):\n",
    "        probability = float((count_of_word + 1)) / float((self.NUM_WORDS[int(num_stars)] + 1))\n",
    "        return probability\n",
    "\n",
    "\n",
    "    # Maps the count of a word, over reviews of the same number of stars,\n",
    "    # to its likelihood: P(WORD | NUM_STARS) = count of WORD / count of ALL words in reviews with NUM_STARS\n",
    "    def counts_to_probabilities(self, num_stars_and_word_counts):\n",
    "        # raise NotImplementedError()\n",
    "        num_stars = num_stars_and_word_counts[0][0]\n",
    "        word = num_stars_and_word_counts[0][1]\n",
    "        ugh = num_stars_and_word_counts[1]\n",
    "        return(num_stars, {word : self.compute_likelihood(ugh, num_stars)})\n",
    "\n",
    "\n",
    "    # Given two probability tables as dictionaries (e.g. {word1: prob1, word2: prob2...}),\n",
    "    # Combines the two tables, by adding the contents of the second table into the first,\n",
    "    # and returning the now updated first table.\n",
    "    def combine_probability_tables(self, word1_and_probability, word2_and_probability):\n",
    "        word1_and_probability.update(word2_and_probability)\n",
    "        return word1_and_probability\n",
    "\n",
    "    # ____________calculate_num_reviews_per_num_stars() helpers________ #\n",
    "\n",
    "\n",
    "    # Converts a review into a pair of its number of stars with the\n",
    "    # number of words in the review and the number of reviews it represents\n",
    "    @staticmethod\n",
    "    def review_to_num_stars_num_words(review):\n",
    "        return (review[1], (1, len(review[2].split(\" \"))))\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "\n",
    "    # Combines the values of two pairs outputted by review_to_num_stars_num_words\n",
    "    @staticmethod\n",
    "    def add_review_and_word_counts(count1, count2):\n",
    "        return (count1[0] + count2[0], count1[1] + count2[1])\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "    # _________________________________________________________ #\n",
    "    # ____________CLASSIFICATION HELPERS_______________________ #\n",
    "    # _________________________________________________________ #\n",
    "\n",
    "    # ____________classify_reviews() helpers____________________ #\n",
    "\n",
    "    # For all words in the review and all possible star ratings for the review,\n",
    "    # returns list of pairs of the possible number of stars, the review's ID, and the word itself.\n",
    "    @staticmethod\n",
    "    def review_to_num_stars_and_word_pairs(review):\n",
    "        review_id, review_text = review\n",
    "        review = review_text.split(\" \")\n",
    "\n",
    "        possible_num_stars_word_pairs = []\n",
    "        for word in review:\n",
    "            possible_num_stars_and_word = [((num_stars, review_id), word) for num_stars in STARS]\n",
    "            possible_num_stars_word_pairs.extend(possible_num_stars_and_word)\n",
    "\n",
    "        return possible_num_stars_word_pairs\n",
    "\n",
    "    # Given a possible number of stars, maps a word to its log-likelihood using self.LIKELIHOODS\n",
    "    # i.e. for WORD and possible NUM_STARS, maps WORD to log(P(WORD | NUM_STARS))\n",
    "    # If WORD is not found in self.LIKELIHOODS, then it has zero likelihood, which after Laplace smoothing,\n",
    "    # maps to a log-likelihood = log(1 / # of total words in reviews with NUM_STARS + 1).\n",
    "    def words_to_log_likelihoods(self, stars_id_word):\n",
    "        num_stars, review_id = int(stars_id_word[0][0]), str(stars_id_word[0][1])\n",
    "        word = str(stars_id_word[1])\n",
    "\n",
    "        likelihoods = self.LIKELIHOODS[num_stars]\n",
    "\n",
    "        if word in likelihoods:\n",
    "            word_likelihood = likelihoods[word]\n",
    "        else:\n",
    "            num_words_with_num_stars = self.NUM_WORDS[num_stars]\n",
    "            word_likelihood = 1.0 / float(num_words_with_num_stars + 1)\n",
    "        log_likelihood = math.log(word_likelihood)\n",
    "\n",
    "        return ((num_stars, review_id), log_likelihood)\n",
    "\n",
    "    # Adds two log-likelihoods together\n",
    "    @staticmethod\n",
    "    def add_log_likelihoods(likelihood1, likelihood2):\n",
    "        return float(likelihood1) + float(likelihood2)\n",
    "\n",
    "    # Given a likelihood, P(WORD | NUM_STARS), calculates the posterior:\n",
    "    # P(WORD, NUM_STARS) = P(WORD | NUM_STARS) * P(NUM_STARS)\n",
    "    # P(NUM_STARS) is stored in self.PRIORS\n",
    "    def likelihood_to_posterior(self, stars_id_lhood):\n",
    "        num_stars, review_id = int(stars_id_lhood[0][0]), stars_id_lhood[0][1]\n",
    "        log_likelihood = float(stars_id_lhood[1])\n",
    "        prior = self.PRIORS[num_stars]\n",
    "        posterior = log_likelihood + math.log(prior)\n",
    "\n",
    "        return ((num_stars, review_id), posterior)\n",
    "\n",
    "    # Modifies key-value pair such that the key only contains the review_id\n",
    "    # All other \"values\" in the key are moved into the value of the pair\n",
    "    @staticmethod\n",
    "    def review_id_only_as_key(stars_id_posterior):\n",
    "        num_stars, review_id = stars_id_posterior[0][0], stars_id_posterior[0][1]\n",
    "        posterior = stars_id_posterior[1]\n",
    "\n",
    "        return (review_id, (num_stars, posterior))\n",
    "\n",
    "\n",
    "    # Returns the max of two posterior probabilities as well as the number of stars\n",
    "    # rating the corresponds to the greater posterior probability\n",
    "    @staticmethod\n",
    "    def find_max_posterior(num_stars_posterior1, num_stars_posterior2):\n",
    "        if (num_stars_posterior1[1] < num_stars_posterior2[1]):\n",
    "            return num_stars_posterior2\n",
    "        return num_stars_posterior1\n",
    "        # raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = YelpClassifier()\n",
    "classifier.train(train_rdd)\n",
    "predictedReviews = classifier.classify(test_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualReviews = get_review_stars(actual_rdd).collect()\n",
    "hits = 0\n",
    "star_hits_dict = {1: 0, 2:0, 3: 0, 4:0, 5: 0}\n",
    "total = 0\n",
    "star_total_dict = {1: 0, 2:0, 3: 0, 4:0, 5: 0}\n",
    "\n",
    "for predicted, actual in zip(predictedReviews, actualReviews):\n",
    "    actualLabel = int(actual[1])\n",
    "#     print(actual, predicted)\n",
    "    predictedLabel = int(predicted[1][0])\n",
    "    if actualLabel == predictedLabel:\n",
    "        star_hits_dict[actualLabel] += 1\n",
    "        hits += 1\n",
    "    star_total_dict[actualLabel] += 1\n",
    "    total += 1\n",
    "\n",
    "accuracy = float(hits) / float(total)\n",
    "one_star_acc = float(star_hits_dict[1]) / float(star_total_dict[1])\n",
    "two_star_acc = float(star_hits_dict[2]) / float(star_total_dict[2])\n",
    "three_star_acc = float(star_hits_dict[3]) / float(star_total_dict[3])\n",
    "four_star_acc = float(star_hits_dict[4]) / float(star_total_dict[4])\n",
    "five_star_acc = float(star_hits_dict[5]) / float(star_total_dict[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\n\\t\\t\\t\\t\\t############################################################\")\n",
    "print(\"\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\")\n",
    "print(\"\\t\\t\\t\\t\\t\\tOVERALL ACCURACY: %f (%d/%d)\\t\\t\" %(accuracy, hits, total))\n",
    "print(\"\\t\\t\\t\\t\\t\\t1 STAR REVIEW ACCURACY: %f (%d/%d)\\t\" \\\n",
    "    %(one_star_acc, star_hits_dict[1], star_total_dict[1]))\n",
    "print(\"\\t\\t\\t\\t\\t\\t3 STAR REVIEW ACCURACY: %f (%d/%d)\\t\" \\\n",
    "    %(two_star_acc, star_hits_dict[2], star_total_dict[2]))\n",
    "print(\"\\t\\t\\t\\t\\t\\t3 STAR REVIEW ACCURACY: %f (%d/%d)\\t\" \\\n",
    "    %(three_star_acc, star_hits_dict[3], star_total_dict[3]))\n",
    "print(\"\\t\\t\\t\\t\\t\\t3 STAR REVIEW ACCURACY: %f (%d/%d)\\t\" \\\n",
    "    %(four_star_acc, star_hits_dict[4], star_total_dict[4]))\n",
    "print(\"\\t\\t\\t\\t\\t\\t5 STAR REVIEW ACCURACY: %f (%d/%d)\\t\" \\\n",
    "    %(five_star_acc, star_hits_dict[5], star_total_dict[5]))\n",
    "print(\"\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\")\n",
    "print(\"\\t\\t\\t\\t\\t############################################################\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
